<<echo=FALSE, cache=FALSE, results='hide'>>=
set_parent('IntroStats.Rnw')
@

\chapter{Confidence Regions} \label{chap:ConfidenceRegions}

\vspace*{-24pt}
\minitoc

<<echo=FALSE>>=
## Functions used below
make.smplingdist <- function(mu,SE,C=0.95) {
  op <- par(mar=(c(0,0,0,0)),las=1,tcl=-0.2)
  z <- qnorm(C+(1-C)/2,0,1)
  x <- seq(mu-4.5*SE,mu+4.5*SE,length.out=200)
  plot(x,dnorm(x,mu,SE),type="l",lwd=3,xlab="",ylab="",axes=FALSE)
  lines(range(x),c(0,0),lwd=2)
  rect(mu-z*SE,0,mu+z*SE,dnorm(mu-2.5*SE,mu,SE),col="green3")
  lines(c(mu,mu),c(0,dnorm(mu,mu,SE)),lty=2)
  par(op)
} # end make.smplingdist

make.CI<-function(mu,SE,C=0.95,num=100) {
  op <- par(mar=(c(0,0,0,0)),las=1,tcl=-0.2,yaxs="i")
  z <- qnorm(C+(1-C)/2,0,1)
  xlmts <- c(mu-4.5*SE,mu+4.5*SE); ylmts <- c(0,num+1)
  plot(0,0,type="l",xlim=xlmts,ylim=ylmts,axes=FALSE)
  lines(c(mu,mu),c(ylmts[1]-10,ylmts[2]+10),lty=2)
  lines(rep(mu-z*SE,2),c(ylmts[1]-10,ylmts[2]+10),lty=2,col="green3")
  lines(rep(mu+z*SE,2),c(ylmts[1]-10,ylmts[2]+10),lty=2,col="green3")
  rect(mu-z*SE,ylmts[1],mu+z*SE,ylmt[2],
       col=col2rgbt("green3",0.05),border=NA,xpd=TRUE)
  for (i in 1:num) {
    xbar <- rnorm(1,mu,SE)
    lci <- xbar-z*SE; uci <- xbar+z*SE
    clr1 <- ifelse(uci<mu | lci>mu,"red","black")
    clr2 <- ifelse(lci>mu | uci<mu,"white",clr1)
    lines(c(lci,uci),c(i,i),col=clr1)
    points(xbar,i,cex=0.5,pch=21,col=clr1,bg=clr2)
  }  #i
  par(op)
} # end make.CI
@

\vspace*{24pt}
\lettrine{T}{he final result from a hypothesis test} \modrefp{chap:HypothesisTests} can feel uneventful -- i.e., either conclude that the parameter may be equal to or different from the hypothesized value.\footnote{Depending on the $H_{A}$ it may be known if the parameter is more or less than the hypothesized value.} If the parameter is thought to be different from the hypothesized value we might then say that our best guess at the parameter is the observed statistic. However, as shown in \modref{chap:SamplingDist}, a statistic is an imperfect estimate of the unknown parameter because of sampling variability. This imperfectness can be recognized by computing a range of values that is likely to contain the parameter. For example, we may make a statement such as this -- ``Our best guess for the true population mean length of fish in Square Lake is the sample mean of 98.5 mm; however, we are 95\% confident that the mean of ALL fish in the lake is between 95.9 and 101.1 mm.''  The range in the last phrase acknowledges sampling variability and is called a confidence region. In this module, the concept, calculation, and interpretation of confidence regions is explored.

\section{Confidence Concept}\label{sect:CIconcept}
An understanding of what it means to be ``95\% confident'' requires examination of multiple samples from a population, as was done in \modref{chap:SamplingDist} when considering sampling variability. In this initial discussion, only 95\% confidence intervals (CI), where a range (i.e., bounded on both ends) is computed, are considered. These simplifying restrictions and unrealistically knowing population values are used here only so that the \textbf{concept} of confidence intervals can be more easily explained. General methods for constructing other types of confidence regions with other levels of confidence are in \sectref{sec:CIConstruct}.

In the Square Lake example (introduced in \modref{chap:WhyStatsImportant}), it was known that $\mu$=98.06 and $\sigma$=31.49 \tabrefp{tab:SquareLakePopn}. Additionally, $\bar{x}=100.04$ was obtained from the first sample of $n$=50 \tabrefp{tab:SquareLakeSample1}. A 95\% CI for $\mu$ is defined as $\bar{x}\pm2SE_{\bar{x}}$. The 95\% CI for the mean total length for the Square Lake population, computed from this one sample, is $100.04\pm2\frac{31.49}{\sqrt{50}}$, $100.04\pm8.91$, or (91.13,108.95). This interval contains $\mu$ (i.e., 98.06 is between 91.13 and 108.95). In other words, this particular CI accomplished what it was intended to do; i.e., provide a range that contains $\mu$.

Despite the success observed in this first sample, not all confidence intervals will contain $\mu$. For example, four of 100 95\% confidence intervals shown in \figref{fig:CIex100} did not contain $\mu$. Thus, the researcher would have concluded that $\mu$ was in an incorrect interval four times in these 100 samples. The concept of ``confidence'' in confidence regions is related to determining how often the intervals correctly contain the parameter.

<<CIex100, echo=FALSE, fig.width=4, fig.height=5, out.width='.5\\linewidth', fig.cap="Sampling distribution of the sample mean (top) and 100 95\\% confidence intervals (horizontal lines) from samples of $n$=50 from the Square Lake population. Confidence intervals that do NOT contain $\\mu$=98.06 are shown in red and with an open circle. The green shaded area represents 95\\% of the sample means. See text for more explanation.">>=
set.seed(20)
# Create new window w/ 2 panes - top is smaller
layout(c(1,2),1,.3)
n <- 50; mu <- 98.06; sigma <- 31.49; SE <- sigma/sqrt(n)
# Calls fnx to make the sampling distribution
make.smplingdist(mu,SE)
# Calls fnx to take samples and make CIs
make.CI(mu,SE)
@

\vspace*{-12pt}
From the Central Limit Theorem, the sampling distribution of $\bar{x}$ for samples of $n$=50 is $N(98.06,\frac{31.49}{\sqrt{50}})$ or $N(98.06,4.45)$ for this known population. According to the 68-95-99.7\% Rule, it is known that 95\% of the sample means in this sampling distribution will be between $\mu\pm2SE$ or, in this specific case, between $98.06\pm2(4.45)$. The sampling distribution and this range of expected sample means is shown at the top of \figref{fig:CIex100}. Note that any sample that produced a mean (dot on the CI line) inside the expected range of sample means (light green area) also produced a 95\% CI that contained $\mu$ (i.e., black CI line with a solid circle). Because 95\% of the sample means will be within the expected range of sample means, 95\% of the 95\% CIs will contain $\mu$. So, ``95\% confident'' means that 95\% of all 95\% CIs will contain the parameter and 5\% will not. In other words, the mistake identified above will be made with 5\% of all 95\% CIs.

The specifics for constructing confidence regions with different levels of confidence is described below. However, at this point, it should be noted that the number of CIs expected to contain the parameter of interest is set by the level of confidence used to construct the CI. For example, 80\% of 80\% CIs and 90\% of 90\% CIs will contain the parameter of interest. In either case, a particular CI either does or does not contain the interval and, in real-life, we will never know whether it does or does not (i.e., we won't know the value of the parameter). However, we do know that the technique (i.e., the construction of the CI) will ``work'' (i.e., contain the parameter) a set percentage of the time. To reiterate this point, examine the 100 90\% CIs (\figref{fig:CI9080Ex}-Left) and 100 80\% CIs (\figref{fig:CI9080Ex}-Right) for the Square Lake fish length data.

<<CI9080Ex, echo=FALSE, fig.width=6, fig.height=4.5, out.width='.92\\linewidth', fig.cap="Sampling distribution of the sample mean (\\textbf{tops}) and 100 random 90\\% (\\textbf{Left}) and 80\\% (\\textbf{Right}) confidence intervals (horizontal lines) from samples of $n$=50 from the Square Lake population. Confidence intervals that do NOT contain $\\mu$ are shown in red.">>=
par(mfrow=c(1,2),mar=c(0,0,0,0),las=1,tcl=-0.2)
set.seed(21)
layout(matrix(c(1,2,3,4),nrow=2,byrow=FALSE),heights=c(0.3,1))
n <- 50; mu <- 98.06; sigma <- 31.49; SE <- sigma/sqrt(n)
make.smplingdist(mu,SE,C=0.9)
make.CI(mu,SE,C=0.9)
make.smplingdist(mu,SE,C=0.8)
make.CI(mu,SE,C=0.8)
@

The concept of confidence regions can be difficult to grasp at first. Thus, one should consider the following subtleties about the concept of a confidence region:

\vspace*{-8pt}
\begin{Itemize}
  \item A CI is a random variable like any other statistic. That is, each sample results in a different 95\% CI (see CI lines in Figures \ref{fig:CIex100} and \ref{fig:CI9080Ex}) just like it results in a different $\bar{x}$ (see dots on CI lines in Figures \ref{fig:CIex100} and \ref{fig:CI9080Ex}).
  \item Any CI either contains the parameter (e.g., $\mu$) or not. However, on average, 95\% of 95\% CIs will contain the parameter and 5\% will not. That is, 95\% of all possible 95\% CIs wil contain the parameter.
  \item A 95\% CI is a technique that ``works correctly'' 95\% of the time. In other words, 95\% of all 95\% CI ``capture'' the unknown parameter.
\end{Itemize}

Because of these subtleties, confidence regions are often misinterpreted. Common misinterpretations are listed below with an explanation for the misinterpretation in parentheses. These misinterpretations should be studied, compared to the interpretations discussed above, and avoided.

\vspace*{-8pt}
\begin{Enumerate}
  \item ``There is a 95\% probability that the population mean is contained in the confidence interval.'' [\textit{This is incorrect because the population mean is constant (not random), it either is or is not in a particular CI, and it will never change whether it is or is not in that CI. The CI, not the parameter, is random.}]
  \item ``There is a 95\% probability that the sample mean is contained in the confidence interval.`` [\textit{This is incorrect for the simple fact that CI are not used to estimate sample means (or, generally, statistics); they are used to estimate population means (or parameters). Furthermore, the sample mean has to be exactly in the middle of the CI (see next section).}]
  \item ``95\% of all 95\% confidence intervals are contained in the confidence interval.'' [\textit{First, this is physically impossible because each CI is the same width (if $n$ and the level of confidence stay constant). Second, it is not important how many CI are contained in a CI; interest is in whether the parameter is in the interval or not.}]
\end{Enumerate}

\vspace{-12pt}
\warn{Confidence intervals are constructed for parameters, not statistics.}

\vspace{-12pt}
\warn{Care and specificity must be used when interpreting and describing confidence intervals.}


\section{Constructing Confidence Regions} \label{sec:CIConstruct}
Not all confidence regions are designed to contain the parameter 95\% ``of the time,'' are intervals, or are computed to contain $\mu$. Confidence regions can be constructed for any level of confidence, as intervals or bounds, and for nearly all \textbf{parameters}.

The level of confidence ($C$) used will be determined by the $\alpha$ chosen for the hypothesis test; specifically, $C=100(1-\alpha)$\%. For example, if $\alpha$ is set at 0.05, then the level of confidence will be $100(1-0.05)$\% \tabrefp{tab:Calpha}. Thus, if $\alpha$ is decreased such that fewer Type I errors are made, then the confidence level will increase and more of the confidence regions will contain the parameter of interest (i.e., fewer errors). In this manner the proportion of Type I errors in hypothesis testing is linked to the proportion of errors made with confidence regions.

\begin{table}[htbp]
\caption{Several common confidence levels ($C$) and the corresponding probability of a Type I error ($\alpha$).}
\label{tab:Calpha}
\centering
\begin{tabular}{cc}
\hline\hline
$\alpha$ & $C$ \\
\hline
0.01 & 99\% \\
0.05 & 95\% \\
0.10 & 90\% \\
\hline\hline
\end{tabular}
\end{table}

The type of confidence region depends on the type of alternative hypothesis \tabrefp{tab:HAsCI}. If the alternative hypothesis is two-tailed (i.e., $\neq$), then the confidence region will be an interval (i.e., a range will be computed, as in \sectref{sect:CIconcept}). However, if the alternative hypothesis is one-tailed, then a confidence bound is used. For example, if the alternative hypothesis is a ``less than'', then interest lies in determining what is the ``largest possible value'' for the parameter (rather than a range of possible values). In other words, if the alternative hypothesis is a ``less than'', then an upper confidence bound for the parameter is constructed. In contrast, if the alternative hypothesis is a ``greater than'', then a lower confidence bound is constructed to estimate the ``smallest possible value'' for the parameter.

\begin{table}[htbp]
\caption{Confidence regions and their interpretation in relation to alternative hypotheses ($H_{A}$) types.}
\label{tab:HAsCI}
\centering
\begin{tabular}{ccc}
\hline\hline
$H_{A}$ & Confidence Region & Interpretation \\
\hline
$\neq$ & Interval & Parameter in interval \\
$<$ & Upper Bound & Parameter less than upper bound \\
$>$ & Lower Bound & Parameter greater than lower bound \\
\hline\hline
\end{tabular}
\end{table}


Fortunately, most confidence regions follow the same basic form of
  \[ \text{``Statistic''} + \text{``scaling factor''} * SE_{statistic} \]
where ``Statistic'' represents the statistic used to estimate the parameter, $SE_{statistic}$ is the standard error of that statistic, and $\text{``scaling factor''}*SE_{statistic}$ is called the margin-of-error. The scaling factor is computed from a known distribution. When $\sigma$ is known, the scaling factor is computed from a $N(0,1)$ and is called $Z^{*}$. Thus, in the case when a confidence interval is being constructed for $\mu$ and $\sigma$ is known, the specific formula for the confidence region is
  \[ \bar{x} + z^{*}\frac{\sigma}{\sqrt{n}} \]

\vspace{-8pt}
The ``scaling factor'' serves to control the width and type of confidence region. The magnitude of the scaling factor controls the relative width of the region such that the parameter is contained in the region at a rate according to the level of confidence. For example, the scaling factor for a 99\% confidence region will be set such that 99\% of the confidence regions will contain the parameter.

The sign of the scaling factor controls whether an interval, upper bound, or lower bound is computed. For example, if the alternative hypothesis is two-tailed, then $Z^{*}$ is the two values such that an area equal to the level of confidence is contained between them (\figref{fig:CIboundsZ}-Left). The two values that delineate these boundaries will be the same value but with different signs because the $N(0,1)$ is symmetric about zero. Thus, a confidence interval is computed with a scaling factor of $\pm Z^{*}$.

<<CIboundsZ, echo=FALSE, fig.width=6, fig.height=2, out.width='.8\\linewidth', fig.cap="Areas (yellow) that define $Z^{*}$ for confidence regions of a parameter in a hypothesis test.">>=
par(mfcol=c(1,3),mar=c(2,0,2,0),las=1,tcl=-0.2)
x0 <- seq(-4,4,length.out=200); norm0 <- dnorm(x0,0,1)
CRegClr <- col2rgbt("yellow",0.3)
ARegClr <- col2rgbt("red",0.3)

plot(x0,norm0,type="l",xlab="",ylab="",axes=FALSE,lwd=3)
mtext(expression(bold(H[A]:mu!=mu[0])),3)
cv1 <- 1.96
xc1 <- c(cv1,x0[x0>=cv1],cv1); yc1 <- c(0,norm0[x0>=cv1],0)
polygon(xc1,yc1,col=ARegClr)
cv2 <- -1.96
xc2 <- c(cv2,x0[x0<=cv2],cv2);  yc2 <- c(0,norm0[x0<=cv2],0)
polygon(xc2,yc2,col=ARegClr)
xc3<-c(cv2,x0[(x0<=cv1 & x0>=cv2)],cv1,cv2)
yc3<-c(0,norm0[(x0<=cv1 & x0>=cv2)],0,0)
polygon(xc3,yc3,col=CRegClr,border="gray30")
lines(x0,norm0,lwd=3)  #redraw lines to cover borders
text(cv2,-0.03,expression(paste(-z,"*")),cex=2,xpd=TRUE)
text(cv1,-0.03,expression(paste(+z,"*")),cex=2,xpd=TRUE)
text(3.2,0.10,expression(frac(alpha,2)),col="blue3",cex=1.5)
arrows(2.8,0.10,2.2,0.01,col="blue3",length=0.1,lwd=2)
text(-3.2,0.10,expression(frac(alpha,2)),col="blue3",cex=1.5)
arrows(-2.8,0.10,-2.2,0.01,col="blue3",length=0.1,lwd=2)
text(0,0.15,expression(C),col="blue3",cex=2)

plot(x0,norm0,type="l",xlab="",ylab="",axes=FALSE,lwd=3)
mtext(expression(bold(H[A]:mu<mu[0])),3)
cv1 <- 1.645
xc1 <- c(cv1,x0[x0>=cv1],cv1); yc1 <-c(0,norm0[x0>=cv1],0)
polygon(xc1,yc1,col=ARegClr)
xc3 <- c(cv1,x0[x0<=cv1],cv1); yc3 <- c(0,norm0[x0<=cv1],0)
polygon(xc3,yc3,col=CRegClr,border="gray30")
lines(x0,norm0,lwd=3)   #redraw lines to cover borders
text(cv1,-0.03,expression(paste(+z,"*")),cex=2,xpd=TRUE)
text(2.8,0.12,expression(alpha),col="blue3",cex=2)
arrows(2.8,0.10,2.2,0.01,col="blue3",length=0.1,lwd=2)
text(0,0.15,expression(C),col="blue3",cex=2)

plot(x0,norm0,type="l",xlab="",ylab="",axes=FALSE,lwd=3)
mtext(expression(bold(H[A]:mu>mu[0])),3)
cv2 <- -1.645
xc2 <- c(cv2,x0[x0<=cv2],cv2); yc2 <- c(0,norm0[x0<=cv2],0)
polygon(xc2,yc2,col=ARegClr)
xc3 <- c(cv2,x0[x0>=cv2],cv2); yc3 <- c(0,norm0[x0>=cv2],0)
polygon(xc3,yc3,col=CRegClr,border="gray30")
lines(x0,norm0,lwd=3)   #redraw lines to cover borders
text(cv2,-0.03,expression(paste(-z,"*")),cex=2,xpd=TRUE)
text(-2.8,0.12,expression(alpha),col="blue3",cex=2)
arrows(-2.8,0.10,-2.2,0.01,col="blue3",length=0.1,lwd=2)
text(0,0.15,expression(C),col="blue3",cex=2)
@

\vspace{-12pt}
In contrast, if the alternative hypothesis is a ``less than'', then an upper confidence bound is desired and $Z^{*}$ has an area equal to the level of confidence LESS THAN it (\figref{fig:CIboundsZ}-Middle). As the level of confidence will always be greater than 50\%, this definition will produce a positive $Z^{*}$ so that the scaling factor will be $+Z^{*}$. Similarly, if the alternative hypothesis is a ``greater than'', then a lower confidence bound is desired and $Z^{*}$ has an area equal to the level of confidence GREATER THAN it (\figref{fig:CIboundsZ}-Right). This definition produces a negative $Z^{*}$ so that the scaling factor will be $-Z^{*}$.

\warn{When finding $Z^{*}$ for a confidence bound, the level of confidence always represents an area shaded in the same direction as the sign in $H_{A}$.}

Constructing a proper confidence region should follow the five steps below. These steps are illustrated in three examples further below.

\vspace*{-12pt}
\begin{Enumerate}
  \item Identify the level of confidence (i.e., $C=100(1-\alpha)$\%; \tabref{tab:Calpha}).
  \item Identify the type of confidence regions -- interval, lower bound, or upperbound \tabrefp{tab:HAsCI}.
  \item Determine the scaling factor.
  \item Compute the actual confidence region.
  \item Interpret the confidence region.
\end{Enumerate}
\vspace*{-4pt}

Consider the Square Lake example where $H_{A}:\mu < 105$, $\alpha=0.05$, and $\bar{x}$=100.04 from $n=50$ \tabrefp{tab:SquareLakeSample1}.

\vspace*{-8pt}
\begin{Enumerate}
  \item $C=95$\% ($100(1-0.05)$).
  \item Upper confidence bound because $H_{A}$ is a ``less than.''
  \item $Z^{*}=+$\Sexpr{formatC(qnorm(0.95),format="f",digits=3)} as found with [Note that \R{mean=0} and \R{sd=1} are the default settings for \R{distrib()} and can, thus, be omitted when finding a $Z^{*}$.]
<<fig.show='hide'>>=
( distrib(0.95,type="q") )
@
\vspace*{6pt}
  \item $100.04+1.645\frac{31.49}{\sqrt{50}}$, $100.04+7.33$, or $107.37$.
  \item One is 95\% confident that the mean total length of ALL fish in Square Lake is less than 107.4 mm. By confident, it is meant that 95\% of all 95\% confidence regions will contain $\mu$.
\end{Enumerate}

Second, suppose that the Lake Superior ice cover data from \tabref{tab:LSIStats} (note that $\bar{x}$=107.8 and $n$=42) was tested with $H_{A}:\mu \neq 100$, $\sigma=22$, and $\alpha=0.01$.

\vspace*{-8pt}
\begin{Enumerate}
  \item $C=99$\% ($100(1-0.01)$).
  \item Confidence interval because $H_{A}$ is a ``not equals.''
  \item $Z^{*}=\pm$\Sexpr{formatC(qnorm(0.995),format="f",digits=3)} as found with
<<fig.show='hide'>>=
( distrib(0.995,type="q") )
@
\vspace*{6pt}
  \item $107.8\pm2.576\frac{22}{\sqrt{42}}$, $107.8\pm8.74$, or $(99.06,116.54)$.
  \item One is 95\% confident that the mean annual number of days of ice cover on Lake Superior is between 99.1 and 116.5 days. By confident, it is meant that 95\% of all 95\% confidence regions will contain $\mu$.
\end{Enumerate}

Finally, suppose that the second example hypothesis test in \modref{chap:HypothesisTests} about battery life (i.e., $H_{A}:\mu>36$ vs $H_{0}:\mu=36$) is being tested with $\alpha=0.10$. Further suppose that $\sigma=$7 and that $\bar{x}=$45 from $n=$40.

\vspace*{-8pt}
\begin{Enumerate}
  \item $C=90$\% ($100(1-0.10)$).
  \item Lower confidence bound because $H_{A}$ is a ``greater than.''
  \item $Z^{*}=$\Sexpr{formatC(qnorm(0.10),format="f",digits=3)} as found with
<<fig.show='hide'>>=
( distrib(0.90,type="q",lower.tail=FALSE) )
@
\vspace*{6pt}
  \item $45-1.282\frac{7}{\sqrt{40}}$, $45-1.42$, or $43.58$
  \item One is 90\% confident that the mean life for ALL batteries with the additive is more than 43.58 months. By confident, it is meant that 95\% of all 95\% confidence regions will contain $\mu$.
\end{Enumerate}


\section[Inference Type Relationship]{Hypothesis Tests and Confidence Region Relationship}
An alternative conceptualization of confidence intervals can show how confidence regions and hypothesis tests are related. This conceptualization rests on considering the sample means that would be ``reasonable to see'' from populations with various values of $\mu$. A graphic is contructed below using the Square Lake population as an example and assuming that $\sigma$ is known (=31.49), $n=50$, and 95\% CIs are used.

First, compute the most common 95\% of sample means assuming that $\mu=70$; i.e., $70 \pm 1.960\frac{31.49}{\sqrt{50}}$ or $(61.27,78.73)$. This range is plotted as a vertical rectangle centered on $\mu=70$ (left-most rectangle) in \figref{fig:CIAlt1}-Left. Next, compute and plot the same range for a slightly larger $\mu$ (e.g., with $\mu=71$, plot $(62.27,78.73)$). Then repeat these steps for sequentially larger values of $\mu$ until a plot similar to \figref{fig:CIAlt1}-Left is constructed.

Consider very carefully what \figref{fig:CIAlt1}-Left represents. The vertical rectangles represent the ranges of the most common 95\% of sample means (values read from the y-axis) that will be produced for a particular population mean (value read from the x-axis). In essence, each vertical line represents the sample means that are likely to be observed from a population with a given population mean (x-axis).

Now suppose that $\bar{x}$=100.04 \tabrefp{tab:SquareLakeSample1}. Draw a horizontal line across \figref{fig:CIAlt1} at this value and then draw vertical lines down from where the horizontal line first enters and last leaves the band of possible sample means (\figref{fig:CIAlt1}-Right). The x-axis values that these vertical lines intercept are an approximate 95\% CI for $\mu$. The approximation is only as close as the intervals used to construct the rectangles (i.e., 1.0 mm were used here). However, the results from this graphical approach (i.e., $(92,108)$) compare favorably to the previous results from using the CI formula (i.e., $(91.27,108.73)$).

<<CIAlt1, echo=FALSE, fig.cap="Range (95\\%) of sample means that would be produced by particular population means in the Square Lake fish length example (\\textbf{Left}) and the ranges intercepted by $\\bar{x}=100.04$ mm (\\textbf{Right}).">>=
sigma <- 31.49; n <- 50; SE <- sigma/sqrt(n)
z <- qnorm(0.975); me <- z*SE
int <- 1; mu <- seq(70,130,int)
res <- matrix(0,nrow=length(mu),ncol=2)
for (i in 1:length(mu)) {
  res[i,1] <- mu[i]-me
  res[i,2] <- mu[i]+me
}

wid <- int/3
plot(0,0,xlim=c(min(mu)-int,max(mu)+int),ylim=range(res),
     xlab="Population Mean",ylab="Sample Mean")
axis(1,at=c(110,130))
for (i in 1:length(mu)) {
  px <- c(rep(mu[i]-wid,2),rep(mu[i]+wid,2),mu[i])
  py <- c(res[i,1],res[i,2],res[i,2],res[i,1],res[i,1])
  polygon(px,py,col="gray")
}

xbar <- 100
plot(0,0,xlim=c(min(mu)-int,max(mu)+int),ylim=range(res),
     xlab="Population Mean",ylab="Sample Mean")
axis(1,at=c(110,130))
for (i in 1:length(mu)) {
  px <- c(rep(mu[i]-wid,2),rep(mu[i]+wid,2),mu[i])
  py <- c(res[i,1],res[i,2],res[i,2],res[i,1],res[i,1])
  if ((xbar>res[i,1]) & (xbar<res[i,2])) {
    polygon(px,py,col="green2")
  } else {
    polygon(px,py,col=col2rgbt("red",0.5))
  }
  abline(h=xbar,lwd=1,col="green2")
}

arrows(mu[23],res[23,2],mu[23],65,length=0.1,angle=20,col="green2")
text(mu[23],67,round(mu[23],1),pos=1)
arrows(mu[39],res[39,2],mu[39],65,length=0.1,angle=20,col="green2")
text(mu[39],67,round(mu[39],1),pos=1)
@

Surely, the CI formula (\sectref{sec:CIConstruct}) is a more efficient and precise way to construct confidence intervals. However, this conceptualization illustrates that a confidence interval (or region, more generally) consists of population means that are likely to produce the observed sample mean. Thus, a confidence region represents possible null hypothesized population means that WOULD NOT BE rejected during hypothesis testing.

\warn{A confidence region represents null hypothesized values that would NOT be rejected.}


\section{Precision and Sample Size}
The width of a confidence interval explains how precisely the parameter is estimated. For example, narrow intervals represent precise estimates of the parameter. The width of a confidence interval is directly related to the margin-of-error which depends on (1) the standard error and (2) the scaling factor. As either of these two items gets smaller (while holding the other constant), the width of the confidence interval gets smaller.

A small standard error means that sampling variability is low and the parameter is precisely estimated by the statistic. Smaller standard errors are obtained only by increasing the sample size. A smaller standard deviation would also result in a smaller SE, but the standard deviation cannot be made smaller (i.e., it is an inherent characteristic of the population).

A smaller scaling factor is obtained by reducing the level of confidence. For example, a 90\% confidence interval uses a $Z^{*}=\pm1.645$ whereas a 95\% confidence interval uses a $Z^{*}=\pm1.960$. Thus, decreasing the confidence level narrows the CI. However, reducing the level of confidence will also increase the number of confidence intervals that do not contain the parameter. Thus, reducing the level of confidence may not be the best choice for narrowing the confidence interval.

The margin-of-error formula can be solved for $n$.
\[
  \begin{split}
    m.e. &= Z^{*}\frac{\sigma}{\sqrt{n}} \\
    \sqrt{n} &= \frac{Z^{*}\sigma}{m.e.} \\
    n &= \left(\frac{Z^{*}\sigma}{m.e}\right)^{2} \\
  \end{split}
\]

This formula can be used to find the $n$ required to estimate $\mu$ within $\pm m.e.$ units with C\% confidence assuming that $\sigma$ is known. For example, suppose that one wants to determine $n$ required to estimate the mean length of fish in Square Lake to within 5 mm with 90\% confidence knowing that the population standard deviation is 34.91. From this, $m.e.$=5, $\sigma$=34.91, and $Z^{*}$=1.645 (found previously for 90\% confidence).\footnote{Strictly, $Z^{*}\pm$=1.645, but the sign is inconsequential due to squaring in the sample size formula.} Thus, $n = \left(\frac{1.645*34.91}{5}\right)^{2} = 131.91$. Therefore, a sample of at least 132 fish from Square Lake should be taken to meet these constraints. Note that sample size calculations are always rounded up to the next integer because rounding down would produce a sample size that does not meet the desired criteria.

\warn{Always round sample size calculations up to the next integer.}

The margin-of-error and confidence level in these calculations need to come from the researcher's beliefs about how much error they can live with (i.e., chance that a confidence interval does not contain the parameter) and how precise their estimate of the mean needs to be. Values for $\sigma$ are rarely known in practice (because it is a parameter) and estimates from preliminary studies, previous similar studies, similar populations, or best guesses are often used instead. In practice, a researcher will often prepare a graph with varying values of $\sigma$ to make an informed decision of what sample size to choose.

<<SampleSizeSigma, echo=FALSE, fig.show='hide', fig.cap='Desired sample size versus margin-of-error for constant values of $\\sigma$ (shown to the left of each line) and $C=90$. The desired sample size for m.e.=5, $\\sigma=35$, and $C=90$ is illustrated with the black dotted lines.'>>=
sigma <- seq(25,50,5); me <- seq(3,10,0.25); z <- qnorm(0.95)
res <- matrix(0,nrow=length(me),ncol=length(sigma))
for (i in 1:length(sigma)) res[,i] <- (z*sigma[i]/me)^2
matplot(me,res,xlab="Margin-of-Error",ylab="Sample Size",type="l",lwd=3,lty=1,xlim=c(2.5,10),yaxt="n",xaxt="n")
axis(1,seq(3,10)); axis(2,seq(0,700,100))
for (i in 1:length(sigma)) { text(2.5,res[1,i],sigma[i],col=i)  }
lines(c(5,5),c(0,res[9,3]),lty=3,lwd=2)
lines(c(5,0),c(res[9,3],res[9,3]),lty=3,lwd=2)
@
