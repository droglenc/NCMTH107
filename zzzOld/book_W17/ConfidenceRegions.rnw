<<echo=FALSE, cache=FALSE, results='hide'>>=
set_parent('IntroStats.Rnw')
@

\chapter{Confidence Regions} \label{chap:ConfidenceRegions}
\begin{ChapObj}{\boxwidth}
  \textbf{Objectives:}
  \begin{Enumerate}
    \item Describe the concept underlying confidence intervals.
    \item Construct confidence intervals for parameters.
    \item Use the confidence interval formula to estimate desired sample sizes.
  \end{Enumerate}
\end{ChapObj}

\minitoc
\vspace{24pt}

<<echo=FALSE>>=
## Functions used below
make.smplingdist <- function(mu,SE,C=0.95) {
  op <- par(mar=(c(0,0,0,0)),las=1,tcl=-0.2)
  z <- qnorm(C+(1-C)/2,0,1)
  x <- seq(mu-4.5*SE,mu+4.5*SE,by=0.1)
  plot(x,dnorm(x,mu,SE),type="l",lwd=3,xlab="",ylab="",axes=F)
  lines(c(min(x),max(x)),c(0,0),lwd=2)
  lpi <- mu-z*SE; upi <- mu+z*SE
  pi.ht <- dnorm(mu-2.5*SE,mu,SE)
  polygon(c(lpi,lpi,upi,upi,lpi),c(0,pi.ht,pi.ht,0,0),col="light green")
  lines(c(mu,mu),c(0,dnorm(mu,mu,SE)),lwd=3,lty=3)
  par(op)
} # end make.smplingdist

make.CI<-function(mu,SE,C=0.95,num=100) {
  op <- par(mar=(c(0,0,0,0)),las=1,tcl=-0.2)
  z <- qnorm(C+(1-C)/2,0,1)
  xlmts <- c(mu-4.5*SE,mu+4.5*SE); ylmts <- c(1,num)
  plot(0,0,type="l",xlim=xlmts,ylim=ylmts,axes=FALSE)
  for (i in 1:num) {
    xbar <- rnorm(1,mu,SE)
    lci <- xbar-z*SE; uci <- xbar+z*SE
    clr <- ifelse(uci<mu,"red",ifelse(lci>mu,"red","blue"))
    lines(c(lci,uci),c(i,i),col=clr)
    points(xbar,i,cex=0.5,pch=19,col=clr)
  }  #i
  lines(c(mu,mu),c(ylmts[1]-10,ylmts[2]+10),lwd=3,lty=3)
  lpi <- mu-z*SE; upi <- mu+z*SE
  lines(c(lpi,lpi),c(ylmts[1]-10,ylmts[2]+10),lwd=2,lty=3,col="green")
  lines(c(upi,upi),c(ylmts[1]-10,ylmts[2]+10),lwd=2,lty=3,col="green")
  par(op)
} # end make.CI
@

\lettrine{T}{he final result from a hypothesis test} \modrefp{chap:HypothesisTests} can feel uneventful -- i.e., either conclude that the parameter may be equal to or different from the hypothesized value.\footnote{Depending on the $H_{A}$ it may be known if the parameter is more or less than the hypothesized value.}  If the parameter is thought to be different from the hypothesized value we might then say that our best guess at the parameter is the observed statistic.  However, as shown in \modref{chap:SamplingDist}, a statistic is an imperfect estimate of the unknown parameter because of sampling variability.  This imperfectness can be recognized by computing a range of values that is likely to contain the parameter.  For example, we may make a statement such as this -- ``Our best guess for the true population mean length of fish in Square Lake is the sample mean of 98.5 mm; however, we are 95\% confident that the mean of ALL fish in the lake is between 95.9 and 101.1 mm.''  The range in the last phrase that acknowledges sampling variability is called a confidence region.  In this module, the concept, calculation, and interpretation of confidence regions is explored.

\section{Confidence Concept}\index{Confidence!Concept} \label{sect:CIconcept}
\vspace{-14pt}
An understanding of what it means to be ``95\% confident'' requires examination of multiple samples from a population as was done when considering sampling variability in \modref{chap:SamplingDist}. In this initial discussion, only 95\% confidence intervals (CI) where a range (i.e., bounded on both ends) is computed are considered. These simplifying restrictions and unrealistically knowing population values are used here only so that the \textbf{concept} of confidence intervals can be more easily explored. General methods for constructing other types of confidence regions with other levels of confidence are in \sectref{sec:CIConstruct}.

In the Square Lake example (introduced in \modref{chap:WhyStatsImportant}), it was known that $\mu$=98.06 and $\sigma$=31.49 \tabrefp{tab:SquareLakePopn} and $\bar{x}=100.04$ from the first sample of $n$=50 \tabrefp{tab:SquareLakeSample1}. A 95\% CI for $\mu$ is defined as $\bar{x}\pm2SE_{\bar{x}}$. Thus, the 95\% CI for the mean total length for the Square Lake population is $100.04\pm2\frac{31.49}{\sqrt{50}}$, $100.04\pm8.91$, or (91.13,108.95).  In this exploratory example, this interval does contain $\mu$.  In other words, this particular CI accomplished what it was intended to do, i.e., provide a range that contains $\mu$.

Despite the success observed in this first sample, not all confidence intervals will contain $\mu$.  For example, four of 100 95\% confidence intervals shown in \figref{fig:CIex100} did not contain $\mu$.  Thus, the researcher would have concluded that $\mu$ was in an incorrect interval four times in these 100 samples.  The concept of ``confidence'' in confidence regions is related to determining how often the intervals correctly contain the parameter.

From the Central Limit Theorem, the sampling distribution of $\bar{x}$ for samples of $n$=50 is $N(98.06,\frac{31.49}{\sqrt{50}})$ or $N(98.06,4.45)$ for this known population.  According to the 68-95-99.7\% Rule, it is known that 95\% of the sample means in this sampling distribution will be between $\mu\pm2SE$ or, in this specific case, between $98.06\pm2(4.45)$.  The sampling distribution and this range of expected sample means is shown at the top of \figref{fig:CIex100}.  In addition, the range of expected sample means is extended down through all of the CI lines in \figref{fig:CIex100}.  Note that any sample that produced a mean (solid dot on the CI line) inside the expected range of sample means also produced a 95\% CI that contained $\mu$ (i.e., blue CI line).  Because 95\% of the sample means will be within the expected range of sample means, 95\% of the 95\% CIs will contain $\mu$.  So, ``95\% confident'' means that 95\% of all 95\% CIs will contain the parameter and 5\% will not.  In other words, the mistake identified above will be made with 5\% of all 95\% confidence intervals.

The specifics for constructing confidence regions with different levels of confidence will be described below.  However, at this point, it should be noted that the number of CIs expected to contain the parameter of interest is set by the level of confidence used to construct the CI.  For example, 80\% of 80\% CIs and 90\% of 90\% CIs will contain the parameter of interest.  In either case, a particular CI either does or does not contain the interval and, in real-life, we will never know whether it does or does not (i.e., we won't know the value of the parameter).  However, we do know that the technique (i.e., the construction of the CI) will ``work'' (i.e., contain the parameter) a set percentage of the time.  To reiterate this point, examine the 100 90\% CIs (\figref{fig:CI9080Ex}-Left) and 100 80\% CIs (\figref{fig:CI9080Ex}-Right) for the Square Lake fish length data.

\warn{The number of confidence intervals expected to contain the parameter of interest is set by the level of confidence used to construct the confidence interval.}

One should consider the following subtleties when considering the concept of a confidence region,
\vspace{-6pt}
\begin{Itemize}
  \item A CI is a random variable like any other statistic. That is, each sample results in a different 95\% CI (see CI lines in \figref{fig:CIex100}) just like it results in a different $\bar{x}$ (see dots on CI lines in \figref{fig:CIex100}).
  \item Any CI either contains the parameter (e.g., $\mu$) or not.  However, on average, 95\% of 95\% CIs will contain the parameter and 5\% will not.  That is, 95\% of all possible 95\% CIs wil contain the parameter.
  \item A 95\% CI is a technique that ``works correctly'' 95\% of the time.  In other words, 95\% of all 95\% CI ``capture'' the unknown parameter.
\end{Itemize}

<<CIex100, echo=FALSE, fig.width=4, fig.height=5, out.width='.6\\linewidth', fig.cap="Sampling distribution of the sample mean (top) and 100 random 95\\% confidence intervals (horizontal lines) from samples of $n$=50 from the Square Lake population.  Confidence intervals that do NOT contain $\\mu$=98.06 are shown in red.">>=
set.seed(20)
# Create new window w/ 2 panes - top is smaller
layout(c(1,2),1,.3)
n <- 50; mu <- 98.06; sigma <- 31.49; SE <- sigma/sqrt(n)
# Calls fnx to make the sampling distribution
make.smplingdist(mu,SE)
# Calls fnx to take samples and make CIs
make.CI(mu,SE)
@

<<CI9080Ex, echo=FALSE, fig.width=6, fig.height=4.5, out.width='.92\\linewidth', fig.cap="Sampling distribution of the sample mean (\\textbf{tops}) and 100 random 90\\% (\\textbf{Left}) and 80\\% (\\textbf{Right}) confidence intervals (horizontal lines) from samples of $n$=50 from the Square Lake population.  Confidence intervals that do NOT contain $\\mu$ are shown in red.">>=
par(mfrow=c(1,2),mar=c(0,0,0,0),las=1,tcl=-0.2)
set.seed(21)
layout(matrix(c(1,2,3,4),nrow=2,byrow=FALSE),heights=c(0.3,1))
n <- 50; mu <- 98.06; sigma <- 31.49; SE <- sigma/sqrt(n)
make.smplingdist(mu,SE,C=0.9)
make.CI(mu,SE,C=0.9)
make.smplingdist(mu,SE,C=0.8)
make.CI(mu,SE,C=0.8)
@

Because of these subtleties, confidence regions are often misinterpreted.\index{Confidence!Common Misinterpretations}  Common misinterpretations are listed below with an explanation for the misinterpretation in parentheses.  These misinterpretations should be studied, compared to the interpretations discussed above, and avoided.
\vspace{-12pt}
\begin{Enumerate}
  \item ``There is a 95\% probability that the population mean is contained in the confidence interval.'' [\textit{This is incorrect because the population mean is constant (not random), it either is or is not in a particular CI, and it will never change whether it is or is not in that CI. The CI, not the parameter, is random.}]
  \item ``95\% of all 95\% confidence intervals are contained in the confidence interval.'' [\textit{First, this is physically impossible at this point (i.e., using $Z^{*}$) because each CI is the same width (if $n$ and the level of confidence stay constant).  Second, it is not important how many CI are contained in a CI; interest is in whether the parameter is in the interval or not.}]
  \item ``There is a 95\% probability that the sample mean is contained in the confidence interval.`` [\textit{This is incorrect for the simple fact that CI are not used to estimate sample means (or, generally, statistics); they are used to estimate population means (or parameters).  Furthermore, the sample mean has to be exactly in the middle of the CI (see next section).}]
\end{Enumerate}

\vspace{-12pt}
\warn{Confidence intervals are constructed for parameters, not statistics.}

\vspace{-12pt}
\warn{Care and specificity must be used when interpreting and describing confidence intervals.}

\vspace{-16pt}
\begin{exsection}
\vspace{-9pt}
  \item \label{revex:CIstat1TF} True or False -- A 95\% confidence region can be constructed for $\bar{x}$? \ansref{ans:CIstat1TF}
  \item \label{revex:CIparam1TF} True or False -- A 95\% confidence region can be constructed for the population median? \ansref{ans:CIparam1TF}
  \item \label{revex:CIparam2TF} True or False -- A 95\% confidence region can be constructed for $\sigma$? \ansref{ans:CIparam2TF}
  \item \label{revex:CIparam3YNC} Yes, No, Can't tell -- Is the estimated parameter in the CI: (111.12, 123.32).  \ansref{ans:CIparam3YNC}
  \item \label{revex:CIparam4C} Replace ``XXX'' to make this statement correct -- ``I am 99\% confident that the XXX of interest is in my confidence interval?'' \ansref{ans:CIparam4C}
\end{exsection}


\section{Constructing Confidence Regions} \label{sec:CIConstruct}\index{Confidence!Intervals}
\vspace{-12pt}
Not all confidence regions are designed to contain the parameter 95\% ``of the time,'' are intervals, or are computed to contain $\mu$.  Confidence regions can be constructed for any level of confidence, as intervals or bounds, and for nearly all \textbf{parameters}.

The level of confidence (C) used will be determined by the $\alpha$ chosen for the hypothesis test.  Specifically, the level of confidence will be $100(1-\alpha)$\%.  For example, if $\alpha$ is set at 0.05, then the level of confidence will be 95\% or if $\alpha$ is set at 0.01, then a 99\% level of confidence will be used.  From this, one can see that if $\alpha$ is decreased such that fewer Type I errors are made, then the confidence level will increase and more of the confidence regions will contain the parameter of interest (i.e., fewer errors).  In this manner the proportion of Type I errors in hypothesis testing is linked to the proportion of errors made with confidence regions.

\warn{The level of confidence (C) is determined from $\alpha$; i.e., $C=100(1-\alpha)$\%.}

The type of confidence region depends on the type of alternative hypothesis.  If the alternative hypothesis is two-tailed (i.e., $\neq$), then the confidence region will be an interval (i.e., a range will be computed, as in \sectref{sect:CIconcept}). However, if the alternative hypothesis is one-tailed, then a confidence bound is used.\index{Confidence!Bounds} For example, if the alternative hypothesis is a ``less than'', then interest lies in determining what is the ``largest possible value'' for the parameter (rather than a range of possible values).  In other words, if the alternative hypothesis is a ``less than'', then an upper confidence bound for the parameter is constructed.  In contrast, if the alternative hypothesis is a ``greater than'', then a lower confidence bound is constructed to estimate the ``smallest possible value'' for the parameter.

\warn{A confidence interval should be constructed when a two-tailed $H_{A}$ is used.}

\vspace{-12pt}
\warn{A confidence bound should be constructed when $H_{A}$ is one-tailed.  If $H_{A}$ is a ``greater than'', then the smallest possible value of the parameter is sought and a lower bound is constructed.  If $H_{A}$ is a ``less than'', then the largest possible value of the parameter is sought and an upper bound is constructed.}

Fortunately, most confidence regions follow the same basic form of
  \[ \text{``Statistic''} + \text{``scaling factor''} * SE_{statistic} \]
where ``Statistic'' represents the statistic used to estimate the parameter, $SE_{statistic}$ is the standard error of that statistic, and $\text{``scaling factor''}*SE_{statistic}$ is called the margin-of-error.\index{Margin-of-Error} The scaling factor is computed from a known distribution. When $\sigma$ is known, the scaling factor is computed from a $N(0,1)$ and is called $Z^{*}$. Thus, in the case when a confidence interval is being constructed for $\mu$ and $\sigma$ is known, the specific formula for the confidence region is
  \[ \bar{x} + z^{*}\frac{\sigma}{\sqrt{n}} \]

The ``scaling factor'' serves to control the width and type of confidence region. The magnitude of the scaling factor controls the relative width of the region such that the parameter is contained in the region at a rate according to the level of confidence.  For example, the scaling factor for a 99\% confidence region will be set such that 99\% of the confidence regions will contain the parameter.

The sign of the scaling factor controls whether an interval, upper bound, or lower bound is computed.  For example, if the alternative hypothesis is two-tailed, then $Z^{*}$ is the two values such that an area equal to the level of confidence is contained between them (\figref{fig:CIboundsZ}-Left).  The two values that delineate these boundaries will be the same value but with different signs because the $N(0,1)$ is symmetric about zero.  Thus, a confidence interval is computed with a scaling factor of $\pm Z^{*}$.

<<CIboundsZ, echo=FALSE, fig.width=6, fig.height=2, out.width='.8\\linewidth', fig.cap="Areas (yellow) that define $Z^{*}$ for confidence regions of a parameter in a hypothesis test.">>=
par(mfcol=c(1,3),mar=c(2,0,2,0),las=1,tcl=-0.2)
x0<-seq(-4,4,by=0.001); norm0<-dnorm(x0,0,1)

plot(x0,norm0,type="l",xlab="",ylab="",axes=F,lwd=3)
mtext(expression(bold(H[A]:mu!=mu[0])),3)
cv1<- 1.96
xc1<-c(cv1,x0[x0>=cv1],cv1); yc1<-c(0,norm0[x0>=cv1],0)
polygon(xc1,yc1,col="red",border="red")
cv2<- -1.96
xc2<-c(cv2,x0[x0<=cv2],cv2);  yc2<-c(0,norm0[x0<=cv2],0)
polygon(xc2,yc2,col="red",border="red")
xc3<-c(cv2,x0[(x0<=cv1 & x0>=cv2)],cv1,cv2); yc3<-c(0,norm0[(x0<=cv1 & x0>=cv2)],0,0)
polygon(xc3,yc3,col="yellow",border="yellow")
lines(x0,norm0,lwd=3)  #redraw lines to cover borders
text(cv2,-0.03,expression(-z),cex=2,xpd=TRUE)
text(cv1,-0.03,expression(+z),cex=2,xpd=TRUE)
text(3.2,0.10,expression(frac(alpha,2)),col="blue",cex=1.5)
arrows(2.8,0.10,2.2,0.01,col="blue",length=0.1,lwd=2)
text(-3.2,0.10,expression(frac(alpha,2)),col="blue",cex=1.5)
arrows(-2.8,0.10,-2.2,0.01,col="blue",length=0.1,lwd=2)
text(0,0.15,expression(C),col="blue",cex=2)

plot(x0,norm0,type="l",xlab="",ylab="",axes=FALSE,lwd=3)
mtext(expression(bold(H[A]:mu<mu[0])),3)
cv1<- 1.645
xc1<-c(cv1,x0[x0>=cv1],cv1); yc1<-c(0,norm0[x0>=cv1],0)
polygon(xc1,yc1,col="red",border="red")
xc3<-c(cv1,x0[x0<=cv1],cv1); yc3<-c(0,norm0[x0<=cv1],0)
polygon(xc3,yc3,col="yellow",border="yellow")
lines(x0,norm0,lwd=3)   #redraw lines to cover borders
text(cv1,-0.03,expression(+z),cex=2,xpd=TRUE)
text(2.8,0.12,expression(alpha),col="blue",cex=2)
arrows(2.8,0.10,2.2,0.01,col="blue",length=0.1,lwd=2)
text(0,0.15,expression(C),col="blue",cex=2)

plot(x0,norm0,type="l",xlab="",ylab="",axes=F,lwd=3)
mtext(expression(bold(H[A]:mu>mu[0])),3)
cv2<- -1.645
xc2<-c(cv2,x0[x0<=cv2],cv2); yc2<-c(0,norm0[x0<=cv2],0)
polygon(xc2,yc2,col="red",border="red")
xc3<-c(cv2,x0[x0>=cv2],cv2); yc3<-c(0,norm0[x0>=cv2],0)
polygon(xc3,yc3,col="yellow",border="yellow")
lines(x0,norm0,lwd=3)   #redraw lines to cover borders
text(cv2,-0.03,expression(-z),cex=2,xpd=TRUE)
text(-2.8,0.12,expression(alpha),col="blue",cex=2)
arrows(-2.8,0.10,-2.2,0.01,col="blue",length=0.1,lwd=2)
text(0,0.15,expression(C),col="blue",cex=2)
@

In contrast, if the alternative hypothesis is a ``less than'', then an upper confidence bound is desired and $Z^{*}$ has an area equal to the level of confidence LESS THAN it (\figref{fig:CIboundsZ}-Middle).  As the level of confidence will always be greater than 50\%, this definition will produce a positive $Z^{*}$ so that the scaling factor will be $+Z^{*}$.  Similarly, if the alternative hypothesis is a ``greater than'', then a lower confidence bound is desired and $Z^{*}$ has an area equal to the level of confidence GREATER THAN it (\figref{fig:CIboundsZ}-Right).  This definition produces a negative $Z^{*}$ so that the scaling factor will be $-Z^{*}$.

\warn{Confidence intervals can be constructed for any level of confidence and for nearly every parameter.}

\vspace{-12pt}
\warn{When finding $Z^{*}$ for a confidence bound, the level of confidence always represents an area shaded in the same direction as the sign in $H_{A}$.}

The following are three examples for calculating confidence regions.
\begin{enumerate}
  \item For the Square Lake example where $H_{A}:\mu < 105$ and $\alpha=0.05$ a 95\% upper confidence bound is constructed.  The corresponding $Z^{*}=+$\Sexpr{formatC(qnorm(0.95),format="f",digits=3)} is found with\footnote{Note that the default settings for \R{distrib()} are to use \R{mean=0} and \R{sd=1}. As these are the defaults, they can be omitted when finding a $Z^{*}$.}
<<fig.show='hide'>>=
( distrib(0.95,type="q") )
@
Thus, with the $\bar{x}$=100.04 from $n=50$ \tabrefp{tab:SquareLakeSample1}, the 95\% upper confidence bound is $100.04+1.645\frac{31.49}{\sqrt{50}}$, $100.04+7.33$, or $107.37$.  Thus, one is 95\% confident that the mean total length of ALL fish in Square Lake is less than 107.4 mm.  By confident, it is meant that 95\% of all 95\% confidence regions will contain $\mu$.

  \item Suppose that the mouse water consumption data from \tabref{tab:MouseData} was tested with $H_{A}:\mu \neq 10$ and $\alpha=0.01$.  In this case, a 99\% confidence interval is computed with $Z^{*}=\pm$\Sexpr{formatC(qnorm(0.995),format="f",digits=3)} as found with
<<fig.show='hide'>>=
( distrib(0.995,type="q") )
@
Thus, assuming that $\sigma=$2 ml and $\bar{x}$=14.04 (from \sectref{sec:quEDACenter}) the 99\% confidence interval is $14.04\pm2.576\frac{2}{\sqrt{30}}$, $14.04\pm0.94$, or $(13.10,14.98)$.  Thus, one is 99\% confident that the mean level of water consumption by ALL mice is between 13.1 and 15.0 ml.  By confident, it is meant that 99\% of all 99\% confidence regions will contain $\mu$.

  \item Suppose that the second example hypothesis test in \modref{chap:HypothesisTests} about battery life (i.e., $H_{A}:\mu>36$ vs $H_{0}:\mu=36$) is being tested with $\alpha=0.10$. Further suppose that $\sigma=$7 and that $\bar{x}=$45 from $n=$40. In this case, a 90\% lower confidence bound is constructed using $Z^{*}=$\Sexpr{formatC(qnorm(0.10),format="f",digits=3)} as found with
<<fig.show='hide'>>=
( distrib(0.90,type="q",lower.tail=FALSE) )
@
Thus, the 90\% lower confidence bound is $45-1.282\frac{7}{\sqrt{40}}$, $45-1.42$, or $43.58$ months.  Thus, one is 90\% confident that the mean life for ALL batteries with the additive is more than 43.58 months.  By confident, it is meant that 90\% of all 90\% confidence regions will contain $\mu$.
\end{enumerate}

\begin{exsection}
  \item \label{revex:CI99zstar} \rhw{} What is $Z^{*}$ for a 99\% confidence interval? \ansref{ans:CI99zstar}
  \item \label{revex:CI92zstar} \rhw{} What is $Z^{*}$ for a 92\% lower confidence bound? \ansref{ans:CI92zstar}
  \item \label{revex:CI90zstar} \rhw{} What is $Z^{*}$ for a 90\% upper confidence bound? \ansref{ans:CI90zstar}
  \item \label{revex:CI98zstar} \rhw{} What is $Z^{*}$ for a 98\% confidence interval? \ansref{ans:CI98zstar}
  \item \label{revex:CI95zstar} \rhw{} What is $Z^{*}$ for a 95\% lower confidence bound? \ansref{ans:CI95zstar}
  \item \label{revex:CI70zstar} \rhw{} What is $Z^{*}$ for a 70\% upper confidence bound? \ansref{ans:CI70zstar}
  \item \label{revex:CIEffluent} \rhw{} Construct and interpret (including describing what is meant by ``confidence'') a proper confidence region for the mean BOD level presented in Review Exercise \ref{revex:HypTEffluent}.  \ansref{ans:CIEffluent}
  \item \label{revex:CIMedSchool} \rhw{} Construct and interpret (including describing what is meant by ``confidence'') a proper confidence region for the mean grade point average presented in Review Exercise \ref{revex:HypTMedSchool}. \ansref{ans:CIMedSchool}
  \item \label{revex:CIBrule} \rhw{} Construct and interpret (including describing what is meant by ``confidence'') a proper confidence region if $H_{A}$ is a ``not equals'' and $\alpha$=0.05 for the population mean gage height on the Bois Brule River presented in Review Exercise \ref{revex:quEDABrule} assuming that the population standard deviation is 0.20 feet and the sampling distribution is approximately normal. \ansref{ans:CIBrule}
  \item \label{revex:CIWIc} \rhw{} Construct and interpret (including describing what is meant by ``confidence'') a proper confidence region if $H_{A}$ is a ``less than'' and $\alpha$=0.10 for the mean population density of all counties in Wisconsin using the data presented in Review Exercise \ref{revex:quEDAWIc} assuming that $\sigma=125$ people/land acre and the sampling distribution is approximately normal. \ansref{ans:CIWIc}
  \item \label{revex:CICreatPhosph} \rhw{} Construct and interpret (including describing what is meant by ``confidence'') a proper confidence region if $H_{A}$ is a ``greater than'' and $\alpha$=0.05 for the population mean creatine phosphokinase value using the data presented in Review Exercise \ref{revex:quEDACreatPhosph} assuming that $\sigma=40$. \ansref{ans:CICreatPhosph}
  \item \label{revex:CIsnow} \rhw{} \cite{Hebblewhite2000} reported the mean snow pack height (in cm) for Banff (data are below).  These data were strongly right-skewed with a possible outlier at the maximum.  Assume that it is known that $\sigma$=15 cm.  (A) Compute a 99\% confidence interval for the mean snow pack height.  (B) In addition, comment on whether or not a confidence interval should be computed for these data (note: compute the CI in (A) regardless of your answer here). \ansref{ans:CIsnow}
  \begin{Verbatim}
29.00,45.51,30.18,45.83,39.54,80.39,32.64,32.89,
46.84,45.79,62.92,67.24,30.96,46.08,33.28
  \end{Verbatim}
\end{exsection}


\section[Inference Type Relationship]{Hypothesis Tests and Confidence Region Relationship}\index{Confidence!Concept}
\vspace{-12pt}
An alternative conceptualization of confidence intervals can show how confidence regions and hypothesis tests are related. This conceptualization rests on considering the sample means that would be ``reasonable to see'' from populations with various values of $\mu$. A graphic is contructed below using the Square Lake population as an example and assuming that $\sigma$ is known (=31.49), $n=50$, and 95\% CIs are used.

First, compute the most common 95\% of sample means assuming that $\mu=70$; i.e., $70 \pm 1.960\frac{31.49}{\sqrt{50}}$, $70 \pm 8.73$, or $(61.27,78.73)$. This range is plotted as a vertical rectangle centered $\mu=70$ (left-most rectangle) in \figref{fig:CIAlt1}-Left). Next, compute and plot the same range for a slightly larger $\mu$ (e.g., with $\mu=71$, plot $(62.27,78.73)$). Then repeat these steps for sequentially larger values of $\mu$ until a plot similar to \figref{fig:CIAlt1} is constructed.

Consider very carefully what \figref{fig:CIAlt1} represents.  The vertical rectangles represent the ranges of the most common 95\% of sample means (values read from the y-axis) that will be produced for a particular population mean (value read from the x-axis).  In essence, each vertical line represents the sample means that are likely to be observed from a population with a given population mean (x-axis).

Now suppose that $\bar{x}$=100.04 is observed as in \tabref{tab:SquareLakeSample1}.  Draw a horizontal line across \figref{fig:CIAlt1} at this value and then draw vertical lines down from where the horizontal line first enters and last leaves the band of possible sample means (\figref{fig:CIAlt1}-Right).  The x-axis values that these vertical lines intercept are an approximate 95\% CI for $\mu$.  The approximation is only as close as the intervals used to construct the rectangles (i.e., 1.0 mm were used here).  However, the results from this graphical approach (i.e., $(92,108)$) compare favorably to the previous results from using the CI formula (i.e., $(91.27,108.73)$).

<<CIAlt1, echo=FALSE, fig.cap="Range (95\\%) of sample means that would be produced by particular population means in the Square Lake fish length example (\\textbf{Left}) and the ranges intercepted by $\\bar{x}=100.04$ mm (\\textbf{Right}).">>=
sigma <- 31.49; n <- 50; SE <- sigma/sqrt(n)
z <- qnorm(0.975); me <- z*SE
int <- 1; mu <- seq(70,130,int)
res <- matrix(0,nrow=length(mu),ncol=2)
for (i in 1:length(mu)) {
  res[i,1] <- mu[i]-me
  res[i,2] <- mu[i]+me
}

wid <- int/3
plot(0,0,xlim=c(min(mu)-int,max(mu)+int),ylim=range(res),
     xlab="Population Mean",ylab="Sample Mean")
axis(1,at=c(110,130))
for (i in 1:length(mu)) {
  px <- c(rep(mu[i]-wid,2),rep(mu[i]+wid,2),mu[i])
  py <- c(res[i,1],res[i,2],res[i,2],res[i,1],res[i,1])
  polygon(px,py,col="gray")
}

xbar <- 100
plot(0,0,xlim=c(min(mu)-int,max(mu)+int),ylim=range(res),
     xlab="Population Mean",ylab="Sample Mean")
axis(1,at=c(110,130))
for (i in 1:length(mu)) {
  px <- c(rep(mu[i]-wid,2),rep(mu[i]+wid,2),mu[i])
  py <- c(res[i,1],res[i,2],res[i,2],res[i,1],res[i,1])
  if ((xbar>res[i,1]) & (xbar<res[i,2])) {
    polygon(px,py,col="green")
  } else {
    polygon(px,py,col="red")
  }
  abline(h=xbar,lwd=1,col="green")
}

arrows(mu[23],res[23,2],mu[23],65,length=0.1,angle=20,col="green")
text(mu[23],67,round(mu[23],1),pos=1)
arrows(mu[39],res[39,2],mu[39],65,length=0.1,angle=20,col="green")
text(mu[39],67,round(mu[39],1),pos=1)
@

Surely, the CI formula (\sectref{sec:CIConstruct}) is a more efficient and precise way to construct confidence intervals.  However, this conceptualization illustrates that a confidence interval (or region, more generally) consists of population means that are likely to produce the observed sample mean.  Thus, a confidence region represents possible null hypothesized population means that WOULD NOT BE rejected during hypothesis testing.

\warn{A confidence region represents population means that would likely have produced the observed sample mean.}

\vspace{-12pt}
\warn{A confidence region represents null hypothesized population means that would NOT be rejected.}


\section{Precision and Sample Size}\index{Sample Size!Estimation} \index{Confidence!Making narrower}\index{Precision}
\vspace{-12pt}
The width of a confidence interval explains how precisely the parameter is estimated.  For example, narrow intervals represent precise estimates of the parameter.  The width of a confidence interval depends on the margin-of-error which depends on (1) the standard error and (2) the scaling factor.  As either of these two items gets smaller (while holding the other constant), the width of the confidence interval gets smaller.

\warn{The width of a confidence interval is a measure how precisely the parameter is estimated.}

\vspace{-12pt}
\warn{The width of a confidence interval depends on the standard error of the statistic and the scaling factor used.}

A small standard error means that sampling variability is low and the parameter is precisely estimated by the statistic.  Smaller standard errors are obtained only by increasing the sample size.\index{Confidence!Effect of n}  A smaller standard deviation would also result in a smaller SE, but the standard deviation cannot be made smaller (i.e., it is an inherent characteristic of the population).

\warn{Confidence intervals can be made narrower by increasing the sample size.}

A smaller scaling factor is obtained by reducing the level of confidence.\index{Confidence!Effect of C}  For example, a 90\% confidence interval uses a $Z^{*}=\pm1.645$ whereas a 95\% confidence interval uses a $Z^{*}=\pm1.960$ (as shown previously).  Thus, decreasing the confidence level narrows the CI.  However, reducing the level of confidence will also increase the number of confidence intervals that do not contain the parameter. Thus, reducing the level of confidence may not be the best choice for narrowing the confidence interval.

\warn{Confidence intervals can (but generally should not) be made narrower by decreasing the level of confidence.}

The relationship between the margin-of-error (m.e.; i.e., width of a confidence interval) and sample size ($n$) provides a means for computing the $n$ required to estimate $\mu$ within $\pm m.e.$ units with C\% confidence assuming that $\sigma$ is known.  Specifically, the margin-of-error formula can be solved for $n$.
\[
  \begin{split}
    m.e. &= z*\frac{\sigma}{\sqrt{n}} \\
    \sqrt{n} &= \frac{z*\sigma}{m.e.} \\
    n &= \left(\frac{z*\sigma}{m.e}\right)^{2} \\
  \end{split}
\]

For example, suppose that one wants the sample size required to estimate the mean length of fish in Square Lake to within 5 mm with 90\% confidence knowing that the population standard deviation is 34.91.  From this, $m.e.$=5, $\sigma$=34.91, and $Z^{*}$=1.645 (found previously for 90\% confidence).\footnote{Strictly, $Z^{*}\pm$=1.645, but the sign is inconsequential due to squaring in the sample size formula.}  Thus, $n = \left(\frac{1.645*34.91}{5}\right)^{2} = 131.91$.  Therefore, a sample of at least 132 fish from Square Lake should be taken to meet these constraints.  Note that sample size calculations are always rounded up to the next integer because rounding down would produce a sample size that does not meet the desired criteria.

\warn{Always round sample size calculations up to the next integer.}

The margin-of-error and confidence level in these calculations need to come from the researcher's beliefs about how much error they can live with (i.e., chance that a confidence interval does not contain the parameter) and how precise their estimate of the mean needs to be.  Values for $\sigma$ are rarely known in practice (because it is a parameter) and estimates from preliminary studies, previous similar studies, similar populations, or best guesses are often used instead.  In practice, a researcher will often prepare a graph with varying values of $\sigma$ to make an informed decision of what sample size to choose \figrefp{fig:SampleSizeSigma}.

<<SampleSizeSigma, echo=FALSE, fig.cap='Desired sample size versus margin-of-error for constant values of $\\sigma$ (shown to the left of each line) and $C=90$.  The desired sample size for m.e.=5, $\\sigma=35$, and $C=90$ is illustrated with the black dotted lines.'>>=
sigma <- seq(25,50,5); me <- seq(3,10,0.25); z <- qnorm(0.95)
res <- matrix(0,nrow=length(me),ncol=length(sigma))
for (i in 1:length(sigma)) res[,i] <- (z*sigma[i]/me)^2
matplot(me,res,xlab="Margin-of-Error",ylab="Sample Size",type="l",lwd=3,lty=1,xlim=c(2.5,10),yaxt="n",xaxt="n")
axis(1,seq(3,10)); axis(2,seq(0,700,100))
for (i in 1:length(sigma)) { text(2.5,res[1,i],sigma[i],col=i)  }
lines(c(5,5),c(0,res[9,3]),lty=3,lwd=2)
lines(c(5,0),c(res[9,3],res[9,3]),lty=3,lwd=2)
@

\begin{minipage}{\textwidth}
\begin{exsection}
  \item \label{revex:CIABn} If two populations have the same standard deviation and a sample of size 30 is taken from population A and a sample of size 50 from population B, which will have a narrower CI? \ansref{ans:CIABn}
  \item \label{revex:CIABs} If the same size of sample is taken from two populations, but Population C has a smaller standard deviation than Population D, which will have a narrower CI? \ansref{ans:CIABs}
  \item \label{revex:CIC} From the same data, is a 95\% or a 99\% CI narrower? \ansref{ans:CIC}
  \item \label{revex:CIdescribe} Describe how the margin of error will change as each of the following change (all others held constant): confidence level (C), z*, $n$, $\sigma$, $\mu$, and $\bar{x}$ (in the case of CIs for $\mu$).  Make sure to explain your reasoning for each. \ansref{ans:CIdescribe}
  \item \label{revex:CIPebbles} Geographers measure the longest axis of pebbles to determine ``grain'' sizes.  If the standard deviation of pebble long-axis length for a particular site is known to be 4 mm, how many pebbles must be measured in order to determine the average pebble length within 0.1 mm with 99\% confidence? \ansref{ans:CIPebbles}
  \item \label{revex:CIISP} An investment group wants to start an Internet Service Provider (ISP) and, for their business plan and model, needs to estimate the average Internet usage of households.  How many households must be randomly selected to be 95\% sure that the sample mean is within 1 minute of the population mean?  Assume that a previous survey of household usage had a standard deviation of 6.95 minutes. \ansref{ans:CIISP}
\end{exsection}
\end{minipage}
